/**
 * Fichier de configuration g√©n√©rale pour l'application Jodotarot
 * Ce fichier centralise tous les param√®tres utilis√©s par l'application pour faciliter la maintenance
 * et √©viter les duplications de code et les incoh√©rences de configuration.
 */

// Configuration de debug
const DEBUG_LEVEL = 1; // 0: aucun, 1: basique, 2: d√©taill√©, 3: verbeux

// Param√®tres utilisateur configurables
const SETTINGS = {
  // Param√®tres d'API
  API_KEY: "YOUR API KEY", // Cl√© API pour OpenAI (laisser vide pour utiliser Ollama)
  ENABLE_STREAMING: true,  // Activer la r√©ception des r√©ponses en temps r√©el
  MAX_TOKENS: 1000,        // Nombre maximum de tokens pour la r√©ponse
  TEMPERATURE: 0.7,        // Temp√©rature (cr√©ativit√©) de la g√©n√©ration
  
  // URLs des services
  OLLAMA_URL: "http://localhost:11434",  // URL du serveur Ollama local
  OPENAI_URL: "https://api.openai.com/v1", // URL de l'API OpenAI
  
  // Param√®tres par d√©faut
  DEFAULT_PERSONA: "tarologue",  // Persona par d√©faut
  DEFAULT_LANGUAGE: "fr",        // Langue par d√©faut
  DEFAULT_DECK: "set01",         // Jeu de cartes par d√©faut
  DEFAULT_SPREAD: "cross",       // Type de tirage par d√©faut
  DEFAULT_MODEL: "mistral-small:latest", // Mod√®le d'IA par d√©faut (utilisation du mod√®le Ollama disponible)
  
  // Param√®tres d'interface
  HIDE_PROMPT: false,      // Masquer le prompt envoy√© √† l'IA
  AUTO_SCROLL: true,       // D√©filement automatique des interpr√©tations
  DARK_MODE: false,        // Mode sombre
};

// Configuration pour l'API OpenAI
const API_KEY = SETTINGS.API_KEY;
const API_URL_OPENAI = `${SETTINGS.OPENAI_URL}/chat/completions`;

// Configuration pour l'API Ollama (local)
const API_URL_OLLAMA = `${SETTINGS.OLLAMA_URL}/api/chat`;
const API_URL_OLLAMA_TAGS = `${SETTINGS.OLLAMA_URL}/api/tags`;

// Configuration des mod√®les Ollama
const OLLAMA_MODEL_FORMATS = {
  // Format de r√©ponse pour chaque famille de mod√®le
  "llama": {
    responseKey: "response"
  },
  "llama3.1": {
    responseKey: "message.content"
  },
  "mistral": {
    responseKey: "message.content"
  },
  "phi": {
    responseKey: "response"
  },
  "gemma": {
    responseKey: "response"
  },
  // Format par d√©faut si aucun match n'est trouv√©
  "default": {
    responseKey: "response"
  }
};

/**
 * Fonction pour obtenir le format de r√©ponse appropri√© pour un mod√®le Ollama
 * @param {string} modelName - Nom du mod√®le (ex: "llama3.1:latest")
 * @returns {Object} - Configuration du format de r√©ponse
 */
function getOllamaModelFormat(modelName) {
  if (!modelName) return OLLAMA_MODEL_FORMATS.default;
  
  // V√©rifier quelle famille de mod√®le correspond
  const lowerModelName = modelName.toLowerCase();
  
  for (const [family, config] of Object.entries(OLLAMA_MODEL_FORMATS)) {
    if (lowerModelName.includes(family)) {
      if (DEBUG_LEVEL > 0) console.log(`üîç DEBUG - Format d√©tect√© pour ${modelName}: ${family}`);
      return config;
    }
  }
  
  // Si aucun match, retourner le format par d√©faut
  if (DEBUG_LEVEL > 0) console.log(`üîç DEBUG - Aucun format sp√©cifique trouv√© pour ${modelName}, utilisation du format par d√©faut`);
  return OLLAMA_MODEL_FORMATS.default;
}

// Exposer SETTINGS globalement pour faciliter l'acc√®s depuis la console de d√©bogage
if (typeof window !== 'undefined') {
  window.JODOTAROT_SETTINGS = SETTINGS;
}

export {
  API_KEY,
  API_URL_OPENAI,
  API_URL_OLLAMA,
  API_URL_OLLAMA_TAGS,
  DEBUG_LEVEL,
  SETTINGS,
  getOllamaModelFormat
}; 